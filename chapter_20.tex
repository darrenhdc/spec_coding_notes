% chapter_20.tex
\small

\section{/resume 的本质与局限}

\subsection*{核心概念：会话级恢复 vs 工程级恢复}

\subsubsection*{/resume 的真正含义}

\texttt{/resume} 的工程语义是：让 Claude 尝试"继续上一次中断的会话状态"，而不是重新理解项目或重新加载工程事实。它是\textbf{会话级恢复}，不是\textbf{工程级恢复}。

\subsubsection*{/resume 恢复的内容}

从工程语义看，\texttt{/resume} 只可能恢复这几类东西：

上一次对话中的：任务目标、讨论上下文、未完成的步骤。

Claude 在当前会话窗口里的：推理轨迹、临时计划、工作节奏。

👉 它恢复的是"对话状态"，不是"项目状态"。

\subsubsection*{/resume 明确不能做的事}

\texttt{/resume} \textbf{不能}：
\begin{itemize}
  \item 恢复你本地的 \texttt{.specify/}
  \item 恢复 \texttt{\textasciitilde{}/.factory/specs/}
  \item 重新读懂你没 commit 的 WIP spec
  \item 替代 ADR / README / CLAUDE.md
  \item 跨账号、跨机器保证一致
\end{itemize}

所以：\texttt{/resume} $\neq$ 工程记忆，\texttt{/resume} $\neq$ 持久状态。

\subsubsection*{工程记忆的层级体系}

\begin{verbatim}
工程事实（长期）
  - ADR
  - README
  - code / tests

AI 行为规则（长期）
  - CLAUDE.md

AI 工具记忆（任务级）
  - .specify/
  - droid specs

会话状态（最脆弱）
  - Claude 当前聊天
  - /resume
\end{verbatim}

👉 \texttt{/resume} 在最底层。

\subsubsection*{适合使用 /resume 的场景}

\textbf{✅ 适合：}刚才断线、页面刷新、模型超时——短时间内、中断不久。

\textbf{❌ 不适合：}隔了一天、换了机器/账号、项目状态有变化——这时 \texttt{/resume} 极不可靠。

\subsubsection*{工程级恢复机制}

\begin{tabular}{lll}
恢复机制 & 恢复什么 & 可靠性 \\
\hline
Git checkout & 工程事实 & ✅✅✅ \\
文档（ADR / WIP） & 工程意图 & ✅✅✅ \\
squash merge & 确定结果 & ✅✅✅ \\
.specify/ & 任务草稿 & ❌ \\
droid specs & 工具草稿 & ❌ \\
/resume & 会话状态 & ❌❌ \\
/session & 会话状态 & ❌❌ \\
\end{tabular}

\subsubsection*{恢复链路}

\begin{verbatim}
项目能否被恢复
   ↓
是否能被 git clone
   ↓
是否能被理解（docs / tests）
   ↓
是否能继续开发
\end{verbatim}

AI 工具的 session / resume \textbf{不在这条链路上}。

\subsection*{判断原则}

任何不能通过 git clone 恢复的 spec，都不是工程级 spec。

/resume 是"聊天续杯"，不是"项目续命"；它能帮你接着说话，但救不了工程记忆。

这是用 AI 做工程时\textbf{最重要的分界线之一}：会话连续性 vs 工程连续性。

\section{Context（上下文）的本质}

\subsection*{对话历史 vs 上下文 vs 模型记忆}

很多人把这三件事混为一谈，但它们不是一回事。

\subsubsection*{context 的工程定义}

context 在工程上指的是：当前一次模型推理时，被送入模型的那一整段输入 token 序列。

它包括：system prompt、开发者指令（如 CLAUDE.md）、用户消息、助手消息（部分或压缩）、工具注入内容。

⚠️ 它只在"这一轮推理"中存在。

\subsubsection*{对话历史的本质}

对话历史是一段文本记录，存在于客户端或服务端数据库。你可以看到，系统可以选择性重放。

👉 它不是 context，本身没有语义能力。

\subsubsection*{隔天继续使用时发生了什么}

当你隔天打开一个"旧对话"时，发生的是：

系统取出之前的对话文本（或其压缩版）$\to$ 把它作为"新输入"重新发送给模型$\to$ 模型重新构建一次 context、重新推理。

👉 这是一次新的推理过程，没有任何"上下文对象"被恢复。

\subsubsection*{为什么 context 不能"显示给用户"？}

因为：
\begin{itemize}
  \item 它不是一个文件
  \item 它是动态拼装的
  \item 包含系统级注入内容
  \item 可能被压缩、截断、重排
\end{itemize}

你看到的只是聊天记录（人类可读），而不是实际送进模型的 token 序列。

\subsubsection*{云端会保留 context 吗？}

严格工程意义上：不会。云端可能会保留对话文本、会话 ID、元数据（时间、模型版本），但：
\begin{itemize}
  \item ❌ 不会保留"上一次推理用过的 context"
  \item ❌ 不会保留"模型内部状态"
\end{itemize}

\subsection*{LLM 是无状态函数}

LLM 是"无状态函数"，所有"状态感"都是通过不断重放文本模拟出来的。

换句话说：
\begin{verbatim}
text + LLM(context) → output
\end{verbatim}

而不是：
\begin{verbatim}
text + LLM(stateful) → output
\end{verbatim}

上下文不是记忆，只是一次性的输入；隔天继续聊天，不是"恢复了过去"，而是"重新讲了一遍故事"。

\section{Copilot Todo List 的本质}

\subsection*{Todo List 的真实属性}

Copilot 的 todo list 本质是：编辑器插件维护的 UI 状态 / 任务提示，而不是：
\begin{itemize}
  \item Git 中的文件
  \item 云端工程文档
  \item 项目级 spec
\end{itemize}

Copilot 的 todo list $\neq$ LLM 的"长期记忆" $\neq$ /resume 的恢复对象。

它更像是 VS Code 插件在当前 workspace、当前 session 或插件本地缓存里维护的一份状态。

\subsection*{Todo List 能否通过 /resume 恢复？}

\textbf{不能保证，通常也不应该指望。}

如果 todo 是你们在聊天中明确列出来的，/resume 可能"接着聊下去"；但如果 todo 是 Copilot UI 自动生成的、插件状态、没有写进 repo / 文档，那它和 /resume 没有工程级关系。

\subsection*{AI 是否有"云端文档仓库"？}

在目前这些工具里（Claude / Copilot / droid），没有一个对用户开放、可审计的"AI 项目文档仓库"。如果有，那一定是明确告诉你存在哪里、怎么导出、怎么版本控制。否则都不是工程级存储。

\subsection*{可审计性判断}

以后你看到任何"AI 帮你记住了 X"，问一句："我现在能不能把它导出、commit、review？"

\begin{itemize}
  \item ✅ 能 $\to$ 工程资产
  \item ❌ 不能 $\to$ 会话幻觉
\end{itemize}

\section{工程文档体系}

\subsection*{文档分层与职责}

\begin{tabular}{lllll}
层级 & 是否工程级 & 是否依赖 Git & 是否可恢复 & 说明 \\
\hline
ADR & ✅ & ✅ & ✅ & 架构与关键决策，最高权威 \\
README & ✅ & ✅ & ✅ & 项目事实与使用方式 \\
PRD & ✅ & ✅ & ✅ & 产品目标与范围 \\
Plan / Design doc & ✅ & ✅ & ✅ & 实现方案与阶段计划 \\
WIP spec & ✅ & ✅ & ✅ & 协作中的未定设计 \\
CLAUDE.md & ✅（AI侧） & ✅ & ✅ & AI 行为与优先级规则 \\
specify / droid specs & ❌ & ❌ & ❌ & 任务级草稿 \\
todo list（Copilot 等） & ❌ & ❌ & ❌ & UI / 会话提示 \\
/resume / /session & ❌ & ❌ & ❌ & 会话连续性 \\
\end{tabular}

\subsection*{PRD（Product Requirements Document）}

\textbf{是什么：}产品目标、用户价值、功能范围、非功能性约束（性能、合规等）

\textbf{工程地位：}工程级、长期有效、必须进 Git、可被新成员 / 新 AI 理解

\textbf{和 ADR 的关系：}PRD 决定"要做什么"，ADR 决定"为什么这样做"

👉 PRD $\neq$ spec 细节，PRD $\neq$ plan

\subsection*{Plan / Design Plan}

\textbf{是什么：}技术方案、模块划分、里程碑、风险评估

\textbf{工程地位：}工程级（但权威低于 ADR / PRD）、可以修改/演进、必须可 review

\textbf{和 WIP 的关系：}WIP 是"讨论态"，Plan 是"阶段共识态"

\subsection*{完整文档优先级}

\begin{enumerate}
  \item ADR (docs/adr/*) -- 不可违反
  \item PRD (docs/prd/*) -- 定义产品目标与边界
  \item README.md -- 项目事实与入口
  \item Plan / Design docs (docs/plan/*) -- 实现路径与阶段策略
  \item WIP specs (docs/wip/*) -- 讨论中内容
  \item CLAUDE.md -- AI 行为与文档优先级声明
  \item Tool-local specs (.specify/, droid) -- 一次性任务草稿
\end{enumerate}

这是一个"无工具绑定、可迁移"的工程模型。

\subsection*{AI 相关机制的"真实位置"}

\textbf{❌ AI 不应该承载：}PRD、Plan、决策理由、todo 的真实来源

\textbf{✅ AI 可以"辅助但不持有"：}拆解 PRD $\to$ Plan、草拟 WIP、生成候选 ADR、提醒遗漏点

👉 最终必须落到 Git 文档里。

\subsection*{为什么 /resume、todo、specify 永远不该升级？}

因为它们：不可审计、不可 review、不可交接、不可复现。而工程的核心是："任何人、任何时间，都能通过仓库理解系统。"

\subsection*{工程记忆的总原则}

凡是定义"是什么 / 为什么 / 要做到什么程度"的 $\to$ 文档；凡是定义"现在这一次怎么做"的 $\to$ 工具；凡是不能被 git clone 恢复的 $\to$ 不算工程资产。

\textbf{最终定锚：}PRD 定义目标，ADR 定义原则，Plan 定义路径；README 讲事实，WIP 承载讨论；CLAUDE.md 约束 AI，specify / todo / resume 只配当草稿。

\section{MCP Tools 与 Function Calling}

\subsection*{核心概念}

函数调用（function calling）是：AI 说"我要用某个函数，并给你参数"。

MCP tools 是："把真实世界的工具，包装成 AI 可以调用的函数"。

👉 MCP $\neq$ 新能力，MCP = 工具标准化接口

\subsection*{函数调用的本质}

想象你在和一个人聊天，你说："帮我查一下今天北京的天气"，对方回答的不是文字，而是：
\begin{verbatim}
{
  "name": "get_weather",
  "arguments": {
    "city": "北京",
    "date": "today"
  }
}
\end{verbatim}

这句话的真实意思是："我判断现在该干活了，而且我知道该用哪个工具，以及该怎么填参数。"

核心点：模型不执行代码、模型只做决定、执行的是你（或系统）。

\subsection*{函数调用 vs 普通对话}

普通对话输出自然语言，给机器用；函数调用输出结构化指令，给机器用。

👉 函数调用 = 给程序看的回答

\subsection*{MCP（Model Context Protocol）}

MCP 是一套"工具怎么描述给 AI 看"的标准。它规定了：这个工具叫什么、有哪些参数、参数是什么类型、返回什么结果。

👉 它让"工具"看起来像"函数"。

以前：每个平台、每个插件、每个 IDE 都有自己的一套工具描述方式。现在：MCP 试图统一这一层。

\subsection*{完整的调用链路}

\begin{verbatim}
你问问题
   ↓
LLM 理解意图
   ↓
LLM 决定：要不要用工具？
   ↓
如果要：输出一个"函数调用"（符合 MCP 描述）
   ↓
宿主系统执行真实工具
   ↓
结果再喂回 LLM
\end{verbatim}

\subsection*{重要认知：MCP 没有赋予 AI 新能力}

AI 不会因为 MCP 就突然能访问数据库或操作文件。能力始终来自你提供的工具。MCP 只是：统一接口、减少胶水代码。

\subsection*{为什么 MCP 比 plugins / actions 更"工程化"？}

因为：明确 schema、明确参数、明确返回值、可以 version、可以 review。你可以：给工具写测试、给工具做 ACL、给工具做审计。

👉 这是工程世界熟悉的东西。

\subsection*{终极比喻}

LLM 是大脑，函数调用是"举手说我要用哪个工具"，MCP 是"工具说明书的统一格式"，执行环境才是真正干活的手。

函数调用是"AI 下达结构化指令"，MCP tools 是"把现实工具翻译成 AI 能点的按钮"。

\subsection*{AI 并没有调用函数}

AI 只是"说出了一次调用指令"。真正发生的是：AI 输出结构化内容 $\to$ 宿主程序看到 name = write\_file $\to$ 宿主程序真的执行 $\to$ 执行结果再交给 AI。

👉 AI 永远不直接碰文件 / 网络 / 数据库。

\subsection*{函数的定义}

函数 = 一个你允许 AI 使用的按钮。这个按钮：有名字、有几个输入框（参数）、点了以后会真的发生事。

\subsection*{为什么要结构化输出？}

因为程序不懂人话。程序看得懂的是：
\begin{verbatim}
{
  "action": "send_email",
  "to": "a@b.com",
  "subject": "Hi"
}
\end{verbatim}

函数调用的本质就是：强迫 AI 用"机器能直接执行的格式说话"。

\subsection*{实例：Claude Code 创建 macOS 提醒事项}

当你用 Claude Code 在 macOS 的「提醒事项」App 里创建新事项，在工程语义上，100\% 就是一次函数调用。

\textbf{第 1 层：AI 的判断（语言 → 意图）}你对 Claude 说："明天早上 8 点提醒我开会"。Claude 理解：这是一个"创建提醒事项"的需求，判断：需要使用系统能力，而不是只回复文字。

\textbf{第 2 层：函数调用（结构化输出）}Claude 输出一个结构化指令，概念上类似：
\begin{verbatim}
{
  "name": "create_reminder",
  "arguments": {
    "title": "开会",
    "date": "2026-01-07",
    "time": "08:00"
  }
}
\end{verbatim}

这是给 Claude Code / 宿主程序看的，不是给你看的自然语言。

\textbf{第 3 层：宿主执行（真的改了系统）}Claude 本身不认识 macOS。发生的是：Claude Code（或插件）把这个调用映射到 macOS Reminders API 或 AppleScript 或 Shortcuts，系统真的创建了提醒事项，执行结果再返回给 Claude。

\subsection*{为什么必须是函数调用？}

因为：可控（你只暴露这一个能力）、可审计（知道 AI 干了什么）、可限制（只能建提醒，不能删文件）。

如果 AI 只是"写命令"给你：你还要手动执行、风险不可控。

\subsection*{最终判断标准}

当 Claude 不再"告诉你怎么做"，而是"直接让系统替你做了"，并且是通过结构化指令完成的，那它就是一次函数调用。
